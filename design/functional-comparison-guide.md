# Functional Oracle Comparison Guide

## Key Paradigm Shift

### OLD APPROACH (oracle_model_comparison.py)
‚ùå "Which model agrees most with CUQ?"
‚ùå Measures CUQ similarity as primary metric
‚ùå Assumes we want to replicate CUQ's world

### NEW APPROACH (oracle_functional_comparison.py)
‚úì "Which model can generate all 8 trajectory types?"
‚úì Measures functional coverage as primary metric
‚úì Accepts we're building a NEW oracle world

## Why This Matters

**CUQ world**: "Train" is indoor (weird but consistent)
**LLM world**: "Train" is outdoor (intuitive and consistent)

**We don't care which world - we just need functional coverage!**

## Priority Metrics (in order)

### 1. Useless Question Rate (<5% CRITICAL)

**What it measures**: % of questions that return all-YES or all-NO (no information)

**Why it matters**: Direct waste of generation budget

**Example**:
- Gemini: 15% useless ‚Üí Generate 50k, only 42.5k useful ‚Üí Waste $10
- GPT-4o mini: 3% useless ‚Üí Generate 50k, 48.5k useful ‚Üí Waste $2
- Claude Sonnet: 2% useless ‚Üí Generate 50k, 49k useful ‚Üí Waste $3

**Thresholds**:
- <5%: ‚úì‚úì‚úì Excellent
- 5-10%: ‚úì Acceptable
- 10-15%: ‚ö†Ô∏è Concerning (but workable)
- >15%: ‚ùå Disqualifying

**Your Gemini result (15%)**: Concerning but not disqualifying if other metrics are good

### 2. Coverage Feasibility (Binary: YES/NO)

**What it measures**: Can you generate all trajectory types (T1-T8) with this oracle?

**How it's tested**:
1. Generate 1000 questions with oracle
2. Run coverage analysis on those bitmasks
3. Check: Do you have enough very_rare, rare, skewed, balanced?
4. Report: Coverage gaps (if any)

**Why it matters**: If you can't generate T4 (needs very_rare), the oracle is useless

**Thresholds**:
- No gaps: ‚úì‚úì‚úì Perfect
- 1-2 gaps: ‚ö†Ô∏è Workable (generate more questions)
- 3+ gaps: ‚ùå Problematic distribution

**Example bad result**:
```
Coverage gaps:
  ‚Ä¢ very_rare: have 15, need 21
  ‚Ä¢ balanced: have 30, need 45
```
‚Üí Need to generate 1.5x more questions

**Example good result**:
```
‚úì All trajectory requirements satisfied
Optimal sample size: 1,281 questions
```
‚Üí Ready to proceed

### 3. Self-Consistency (>95% target)

**What it measures**: If you ask the same question twice, do you get the same answer?

**How it's tested**:
1. Sample 50 questions
2. Query oracle 2-3 times for each
3. Measure: % of question-item pairs with consistent answers

**Why it matters**: Inconsistent oracle means noisy training data

**Thresholds**:
- >95%: ‚úì‚úì‚úì Highly deterministic
- 90-95%: ‚úì‚úì Good (mostly consistent)
- 85-90%: ‚úì Acceptable (some variance)
- <85%: ‚ö†Ô∏è Problematic (set temperature=0 or use voting)

**Example**:
- Question: "Is it edible?"
- Item: "Banana"
- Query 1: YES
- Query 2: YES
- Query 3: YES
- ‚Üí 100% consistent ‚úì

**If inconsistent (70%)**: Oracle has high sampling variance ‚Üí need deterministic generation

### 4. Distribution Shape (Not absolute values!)

**What it measures**: Does oracle have SOME of each bucket?

**What we DON'T care about**:
- ‚ùå CUQ has 4.4% balanced, oracle has 8% ‚Üí IRRELEVANT
- ‚ùå CUQ has 20% very_rare, oracle has 5% ‚Üí IRRELEVANT

**What we DO care about**:
- ‚úì Oracle has >1% very_rare (can generate T4)
- ‚úì Oracle has >2% balanced (can generate T1, T6, T7, T8)
- ‚úì Oracle has >1% rare (can generate T2, T7)
- ‚úì Oracle has >1% skewed (can generate T5)

**Pathological distributions**:
- 0% balanced ‚Üí Can't generate T1/T6/T7/T8 ‚ùå
- 90% very_rare ‚Üí Hard to find balanced questions ‚ö†Ô∏è
- 100% all-YES ‚Üí Oracle is broken ‚ùå

**Example good result**:
```
very_rare: 8.2%   ‚úì (>1%)
rare: 12.1%       ‚úì (>1%)
skewed: 35.4%     ‚úì (>1%)
balanced: 44.3%   ‚úì (>2%)
```
‚Üí Has all buckets, good shape

**Example bad result**:
```
very_rare: 0.1%   ‚ö†Ô∏è (too few)
balanced: 0.8%    ‚ö†Ô∏è (too few)
```
‚Üí Will struggle with T4 and T1 trajectories

### 5. Cost per Useful Question

**What it measures**: $/1000 questions after accounting for waste

**Formula**: `cost_per_1k / (1 - useless_rate)`

**Why it matters**: True cost accounting

**Example**:
- Gemini: $1.41/1k raw, 15% useless ‚Üí $1.66/1k useful (+18% hidden cost)
- GPT-4o mini: $1.92/1k raw, 3% useless ‚Üí $1.98/1k useful (+3% hidden cost)
- Claude Sonnet: $3.50/1k raw, 2% useless ‚Üí $3.57/1k useful (+2% hidden cost)

**This is why useless rate matters**: High waste increases effective cost

## Functional Quality Score

Composite metric (0-1 scale):

```
Quality = 0.30 √ó low_useless_rate
        + 0.30 √ó coverage_feasible
        + 0.20 √ó self_consistency
        + 0.10 √ó has_balanced
        + 0.10 √ó has_very_rare
```

**Interpretation**:
- >0.85: ‚úì‚úì‚úì Excellent for trajectory generation
- 0.75-0.85: ‚úì‚úì Good, will work well
- 0.65-0.75: ‚úì Acceptable, may need adjustments
- 0.50-0.65: ‚ö†Ô∏è Marginal, consider alternatives
- <0.50: ‚ùå Poor, not recommended

## Expected Results

Based on your preliminary findings:

| Model | Useless Rate | Coverage | Consistency | Quality | Verdict |
|-------|--------------|----------|-------------|---------|---------|
| Gemini Flash | 15% | ? | ? | ~0.70 | ‚ö†Ô∏è Marginal |
| GPT-4o mini | 3%* | ? | ? | ~0.85 | ‚úì‚úì Likely best |
| Claude Sonnet | 2%* | ? | ? | ~0.88 | ‚úì‚úì‚úì Premium |

*Estimated - needs testing

## How to Interpret Output

### Example Output 1: Clear Winner

```
RECOMMENDATION: gpt4o_mini
Functional Quality: 0.847

‚úì Key Strengths:
  ‚Ä¢ Low waste: Only 3.2% useless questions
  ‚Ä¢ Complete coverage: Can generate all trajectory types
  ‚Ä¢ Needs 1,450 questions for 95% confidence
  ‚Ä¢ Highly consistent: 97.8% deterministic
  ‚Ä¢ Cost: $55.68 for optimal coverage
```

**Action**: Use GPT-4o mini, generate 1,450 questions

### Example Output 2: High Useless Rate

```
RECOMMENDATION: gemini_flash_2.0
Functional Quality: 0.723

‚ö†Ô∏è Watch Out For:
  ‚Ä¢ 15.3% useless questions (~$8.55 wasted)
    ‚Üí Consider prompt refinement or post-generation filtering
  
üìã Examples of Problematic Questions:
  ‚Ä¢ q_044: 'can be used to sculpt' (128/128 YES)
  ‚Ä¢ q_014: 'able to be used for art' (128/128 YES)
  ‚Ä¢ q_030: 'relates to historical figure' (91/128 YES)
```

**Action**: 
1. Refine prompt: "Answer NO unless property clearly and literally applies"
2. Re-test with refined prompt
3. If still >10% useless, switch to GPT-4o mini

### Example Output 3: Coverage Gaps

```
RECOMMENDATION: claude_sonnet_4
Functional Quality: 0.812

‚ö†Ô∏è Watch Out For:
  ‚Ä¢ Coverage gaps detected:
      balanced: have 18, need 45
      very_rare: have 15, need 21
    ‚Üí May need to generate more questions or bias toward missing buckets
```

**Action**:
1. Generate 2x more questions (2,820 instead of 1,410)
2. Or bias generation toward balanced/very_rare questions
3. Re-run coverage analysis to verify

### Example Output 4: Low Consistency

```
RECOMMENDATION: gemini_flash_2.0
Functional Quality: 0.759

‚ö†Ô∏è Watch Out For:
  ‚Ä¢ Moderate consistency: 87.4%
    ‚Üí May need to set temperature=0 or use majority voting
```

**Action**:
1. Set temperature=0 in API calls
2. Or use best-of-3 voting for each question
3. Re-test consistency

## Comparison to Old Script

### Old Script (oracle_model_comparison.py)

**Primary metric**: Agreement with CUQ (84%)
**Secondary**: Split distribution match to CUQ
**Output**: "Gemini has 84% agreement with CUQ"
**Conclusion**: ‚ùì Is 84% good enough? Unclear.

### New Script (oracle_functional_comparison.py)

**Primary metric**: Useless rate (15%)
**Secondary**: Coverage feasibility (YES/NO)
**Output**: "Gemini wastes 15% of budget but covers all trajectory types"
**Conclusion**: ‚úì Actionable - reduce waste or accept cost

## When to Use Each Script

### Use OLD script if:
- You want to stay close to CUQ oracle world
- You have specific reasons to preserve CUQ's world model
- You're debugging CUQ oracle issues

### Use NEW script if:
- You're building a new oracle (most cases)
- You care about trajectory generation capability
- You want to minimize wasted generation budget
- You're deciding between multiple LLM oracles

## Implementation Checklist

- [ ] Prepare 1000 test questions (diverse sample from your full set)
- [ ] Implement `load_test_questions()` function
- [ ] Implement `query_oracle_with_consistency_test()` for each model
- [ ] Run script: `python oracle_functional_comparison.py`
- [ ] Review useless rate (target: <5%)
- [ ] Check coverage feasibility (target: no gaps)
- [ ] Verify self-consistency (target: >95%)
- [ ] Compare costs
- [ ] Make decision
- [ ] If needed: refine prompts and re-test
- [ ] Generate full dataset with chosen model

## Cost Estimate

**Test run (1000 questions √ó 3 models)**:
- Gemini Flash: $0.22
- GPT-4o mini: $0.38
- Claude Sonnet: $7.68
- **Total: ~$8.30**

Plus 2x for consistency testing = **~$16.60 total**

Worth it to avoid wasting $50-100 on wrong model!

## Quick Decision Matrix

| Useless Rate | Coverage | Consistency | ‚Üí Decision |
|--------------|----------|-------------|------------|
| <5% | ‚úì | >95% | ‚úì‚úì‚úì USE IT |
| <5% | ‚úì | 85-95% | ‚úì‚úì Use with temp=0 |
| <10% | ‚úì | >95% | ‚úì Acceptable |
| 10-15% | ‚úì | >95% | ‚ö†Ô∏è Try prompt refinement first |
| >15% | Any | Any | ‚ùå Switch models |
| Any | ‚úó | Any | ‚ùå Switch models |
| <5% | ‚úì | <85% | ‚ö†Ô∏è Need voting/temperature fix |

## Bottom Line

**Old question**: "Does this match CUQ?"
**New question**: "Can I build trajectories with this?"

The new script answers the question you actually care about.
