{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Belief Trajectory Generator","text":"<p>Synthetic trajectory generator for 20 Questions games that stress-test specific MAST failure modes.</p>"},{"location":"#what-is-this","title":"What is this?","text":"<p>This toolkit generates trajectories for a 20 Questions game where:</p> <ul> <li>An oracle knows a secret item (one of 128 possibilities)</li> <li>A guesser asks yes/no questions to identify the secret</li> <li>Each question partitions the feasible set based on the oracle's answer</li> </ul> <p>The trajectories are designed to exhibit specific failure patterns that can be used to:</p> <ol> <li>Train models to recognize epistemic uncertainty</li> <li>Evaluate model calibration and termination decisions</li> <li>Generate reward signals for RL-based correction</li> </ol>"},{"location":"#trajectory-archetypes-t1-t8","title":"Trajectory Archetypes (T1-T8)","text":"Type Pattern MAST Mode Use Case T1 Smooth halving baseline Control condition T2 Early collapse FM-2.6 Prediction-belief mismatch T3 Plateau \u2192 resolution FM-3.1 Premature termination T4 Redundant loop FM-1.3 Step repetition T5 Multi-modal FM-2.2 Ambiguity handling T6 Prediction mismatch FM-2.6 Calibration failure T7 Late shock FM-3.1 Confidence collapse T8 Wrong verification FM-3.3 Incorrect verification"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Generate a single trajectory\npython run.py single --type T8 --termination wrong_guess\n\n# Batch generation\npython run.py batch --count 800 --distribution uniform --output-dir outputs/\n\n# Validate trajectories\npython run.py validate outputs/ --show-failures\n</code></pre>"},{"location":"#key-concepts","title":"Key Concepts","text":""},{"location":"#state-space","title":"State Space","text":"<p>At each turn, the state is:</p> <ul> <li>H - Entropy (bits of uncertainty remaining)</li> <li>|S| - Feasible set size (number of possible secrets)</li> <li>History - Sequence of (question, answer) pairs</li> </ul>"},{"location":"#action-space","title":"Action Space","text":"<p>The guesser can:</p> <ul> <li>ASK(question) - Ask a yes/no question</li> <li>GUESS(item) - Commit to a final answer</li> </ul>"},{"location":"#failure-modes","title":"Failure Modes","text":"<p>MAST failure modes categorize how agents fail:</p> <ul> <li>FM-1.x - Specification failures (wrong actions)</li> <li>FM-2.x - Belief failures (miscalibration)</li> <li>FM-3.x - Verification failures (bad termination)</li> </ul> <p>See MAST Failure Modes for details.</p>"},{"location":"BELIEF_PROBE_NOTES/","title":"Belief Probe Baseline Notes","text":"<p>Date: 2026-01-18</p>"},{"location":"BELIEF_PROBE_NOTES/#overview","title":"Overview","text":"<p>Built a belief probe system to measure divergence between behavioral belief (token distribution at decision point) and declarative belief (self-reported probabilities) under four probe orderings.</p>"},{"location":"BELIEF_PROBE_NOTES/#probes","title":"Probes","text":"Probe Order Purpose A Act \u2192 Report Post-hoc honesty B Report \u2192 Act Belief anchoring C CoT \u2192 Act Reasoning propagation D Act \u2192 Introspect Retrospective report"},{"location":"BELIEF_PROBE_NOTES/#key-findings","title":"Key Findings","text":""},{"location":"BELIEF_PROBE_NOTES/#1-uniform-report-attractor","title":"1. Uniform Report Attractor","text":"<p>Without constraints, models output uniform <code>{\"A\":25,\"B\":25,\"C\":25,\"D\":25}</code> regardless of action distribution. This is a learned \"safe\" policy under RLHF.</p> <p>Fix: Anti-uniform constraint (5-80% per option) breaks the attractor without inducing boundary gaming.</p>"},{"location":"BELIEF_PROBE_NOTES/#2-cot-effectiveness-is-question-dependent","title":"2. CoT Effectiveness is Question-Dependent","text":"Category Best Probe CoT (C) Performance Easy C (CoT) JS=0.072 \u2014 best Ambiguous D (Introspect) JS=0.334 \u2014 worst Adversarial D (Introspect) JS=0.316 \u2014 worst <p>CoT acts as a variance amplifier: good when there's a crisp answer, bad when multiple answers are valid.</p>"},{"location":"BELIEF_PROBE_NOTES/#3-logprobs-vs-sampling-show-opposite-correlations","title":"3. Logprobs vs Sampling Show Opposite Correlations","text":"Method Corr(JS, H_token) Meaning Sampling (Ollama) +0.33 JS\u2191 when uncertain Logprobs (OpenAI/Gemini) -0.50 JS\u2191 when confident <p>With true logprobs, divergence is highest when the model is most confident \u2014 revealing \"confident action, hedged report\" pattern.</p>"},{"location":"BELIEF_PROBE_NOTES/#4-probe-b-wins-across-providers","title":"4. Probe B Wins Across Providers","text":"<p>Report-first (B) consistently shows lowest JS divergence, confirming the anchoring effect works across model families.</p>"},{"location":"BELIEF_PROBE_NOTES/#files","title":"Files","text":"<pre><code>belief_probe_baseline.py   # Main probe harness (Ollama)\nproviders.py               # Provider-agnostic interface\ncompare_providers.py       # Cross-provider comparison\ngenerate_mc_questions.py   # Question generator\nmc_questions.json          # 40 test questions\nexperiment2_results.json   # Ollama multi-question results\nprovider_comparison.json   # OpenAI/Gemini comparison\n</code></pre>"},{"location":"BELIEF_PROBE_NOTES/#next-steps-not-yet-implemented","title":"Next Steps (Not Yet Implemented)","text":"<ol> <li>Experiment 1: Sweep constraint bounds [1%,95%], [5%,80%], [10%,70%]</li> <li>Experiment 3: Add Probe E (Report \u2192 CoT \u2192 Act)</li> <li>Calibration metrics: Report accuracy vs action agreement</li> <li>20Q integration: Use probes at trajectory inflection points</li> </ol>"},{"location":"BELIEF_PROBE_NOTES/#usage","title":"Usage","text":"<pre><code># Single probe run with anti-uniform\npython belief_probe_baseline.py llama3.1:latest --anti-uniform -n 50\n\n# Multi-question experiment\npython belief_probe_baseline.py --experiment2 --anti-uniform -o results.json\n\n# Cross-provider comparison\npython compare_providers.py --providers openai gemini --quick\n</code></pre>"},{"location":"GATE_PASS_REGRESSION_REPORT/","title":"Gate Pass Rate Report","text":"<p>Date: 2026-01-18 Status: All issues resolved</p>"},{"location":"GATE_PASS_REGRESSION_REPORT/#final-pass-rates","title":"Final Pass Rates","text":"Type Pass Rate Notes T1 94% OK T2 100% OK T3 100% OK T4 100% OK T5 100% OK T6 100% OK T7 100% Fixed (relaxed constraint + validator) T8 100% Fixed (auto-apply <code>wrong_guess</code> overlay)"},{"location":"GATE_PASS_REGRESSION_REPORT/#fixes-applied","title":"Fixes Applied","text":""},{"location":"GATE_PASS_REGRESSION_REPORT/#t7-late-shock","title":"T7: Late Shock","text":"<p>Problem: Shock constraint required 0.85-0.98 split ratio, which is impossible with small |S| (e.g., |S|=4 only allows ratios {0.25, 0.5, 0.75}).</p> <p>Fixes: 1. <code>src/generators/archetypes.py</code>: Relaxed shock split ratio from 0.85-0.98 to 0.70-0.95 2. <code>src/generators/archetypes.py</code>: Increased floor from 4 to 8 items before shock 3. <code>src/validators.py</code>: Relaxed validator to check last 4 turns instead of last 2</p>"},{"location":"GATE_PASS_REGRESSION_REPORT/#t8-wrong-verification","title":"T8: Wrong Verification","text":"<p>Problem: Required <code>--termination wrong_guess</code> flag to generate verification claims.</p> <p>Fix: <code>run.py</code>: Added <code>DEFAULT_TERMINATION_OVERLAYS</code> to auto-apply <code>wrong_guess</code> for T8.</p>"},{"location":"GATE_PASS_REGRESSION_REPORT/#test-commands","title":"Test Commands","text":"<pre><code># Verify all pass rates\npython -c \"\nfrom src.loader import load_cuq_dataset\nfrom src.generators import PathFirstGenerator, SecretFirstGenerator\nfrom src.validators import validate_trajectory\n\ndataset = load_cuq_dataset('data/questions_gpt4o_mini.jsonl', 'data/items.txt')\n\nfor ttype in ['T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7']:\n    Gen = SecretFirstGenerator if ttype in ['T1', 'T6'] else PathFirstGenerator\n    passed = sum(1 for i in range(50) if validate_trajectory(Gen(dataset, seed=i).generate(ttype)).passed)\n    print(f'{ttype}: {passed}/50 ({passed*2}%)')\n\"\n\n# T8 via CLI (overlay applied automatically)\npython run.py batch --type T8 --count 10 --output-dir /tmp/t8_test\n</code></pre>"},{"location":"TURN_SCHEMA/","title":"Turn Schema","text":"<p>Schema documentation for trajectory turns in the belief trajectory generator.</p>"},{"location":"TURN_SCHEMA/#trajectoryturn","title":"TrajectoryTurn","text":"<p>A single turn in a 20 Questions game trajectory.</p>"},{"location":"TURN_SCHEMA/#core-fields","title":"Core Fields","text":"Field Type Required Description <code>turn</code> integer yes Turn number (1-indexed) <code>question_id</code> integer yes Reference to question in the pool <code>question</code> string yes The question text asked <code>answer</code> boolean yes Oracle answer: <code>true</code> = YES, <code>false</code> = NO"},{"location":"TURN_SCHEMA/#feasible-set-tracking","title":"Feasible Set Tracking","text":"Field Type Required Description <code>feasible_set_size_before</code> integer yes Number of possible secrets before this turn <code>feasible_set_size_after</code> integer yes Number of possible secrets after this turn"},{"location":"TURN_SCHEMA/#entropy-tracking","title":"Entropy Tracking","text":"Field Type Required Description <code>entropy_before</code> float yes Shannon entropy (bits) before this turn <code>entropy_after</code> float yes Shannon entropy (bits) after this turn <p>Note: Entropy is computed as <code>log2(feasible_set_size)</code> assuming uniform distribution.</p>"},{"location":"TURN_SCHEMA/#split-characteristics","title":"Split Characteristics","text":"Field Type Required Description <code>split_ratio</code> float yes Proportion of feasible set answering YES (0.0-1.0) <code>branch_taken</code> string yes Which branch was followed: <code>\"yes\"</code> or <code>\"no\"</code> <code>branch_probability</code> float yes Probability of the taken branch <p>Split ratio interpretation: - <code>0.5</code> = balanced split (maximum information gain) - <code>0.0</code> or <code>1.0</code> = no-op question (zero information gain) - <code>&lt; 0.1</code> or <code>&gt; 0.9</code> = extreme split (potential shock)</p>"},{"location":"TURN_SCHEMA/#action-channel-termination","title":"Action Channel (Termination)","text":"Field Type Required Description <code>model_action</code> string yes Action taken: <code>\"continue\"</code>, <code>\"guess\"</code>, or <code>\"stop\"</code> <code>guess</code> Guess no Present if <code>model_action == \"guess\"</code> <code>guess_correct</code> boolean no Whether the guess was correct <code>stop_reason</code> string no Reason for stopping (if stopped) <code>stop_accepted</code> boolean no Whether the stop was valid"},{"location":"TURN_SCHEMA/#belief-report-channel-prediction","title":"Belief-Report Channel (Prediction)","text":"Field Type Required Description <code>prediction</code> Prediction no Model's prediction for this turn"},{"location":"TURN_SCHEMA/#state-tracking-optional","title":"State Tracking (Optional)","text":"Field Type Required Description <code>state_before_hex</code> string no Hex-encoded 128-bit feasible set bitmask <code>question_bitmask_hex</code> string no Hex-encoded 128-bit question bitmask"},{"location":"TURN_SCHEMA/#guess","title":"Guess","text":"<p>A guess action by the model.</p> Field Type Required Description <code>secret_index</code> integer yes Index of guessed item (0-127) <code>secret</code> string yes Name of guessed item <code>confidence</code> float yes Model confidence (0.0-1.0) <code>verification_claim</code> string no Verification statement (for FM-3.3 wrong verification)"},{"location":"TURN_SCHEMA/#prediction","title":"Prediction","text":"<p>Model's belief-report for a turn.</p> Field Type Required Description <code>predicted_answer</code> boolean yes Predicted answer: <code>true</code> = YES, <code>false</code> = NO <code>confidence</code> float yes Confidence in prediction (0.0-1.0)"},{"location":"TURN_SCHEMA/#example-turn","title":"Example Turn","text":"<pre><code>{\n  \"turn\": 4,\n  \"question_id\": 12847,\n  \"question\": \"Is it used for decoration?\",\n  \"answer\": false,\n  \"feasible_set_size_before\": 12,\n  \"feasible_set_size_after\": 8,\n  \"entropy_before\": 3.58,\n  \"entropy_after\": 3.0,\n  \"split_ratio\": 0.33,\n  \"branch_taken\": \"no\",\n  \"branch_probability\": 0.67,\n  \"model_action\": \"continue\",\n  \"prediction\": {\n    \"predicted_answer\": false,\n    \"confidence\": 0.72\n  }\n}\n</code></pre>"},{"location":"TURN_SCHEMA/#example-turn-with-guess","title":"Example Turn with Guess","text":"<pre><code>{\n  \"turn\": 12,\n  \"question_id\": 45231,\n  \"question\": \"Is it a fruit?\",\n  \"answer\": true,\n  \"feasible_set_size_before\": 3,\n  \"feasible_set_size_after\": 1,\n  \"entropy_before\": 1.58,\n  \"entropy_after\": 0.0,\n  \"split_ratio\": 0.33,\n  \"branch_taken\": \"yes\",\n  \"branch_probability\": 0.33,\n  \"model_action\": \"guess\",\n  \"guess\": {\n    \"secret_index\": 87,\n    \"secret\": \"Watermelon\",\n    \"confidence\": 0.95,\n    \"verification_claim\": null\n  },\n  \"guess_correct\": true,\n  \"prediction\": {\n    \"predicted_answer\": true,\n    \"confidence\": 0.88\n  }\n}\n</code></pre>"},{"location":"TURN_SCHEMA/#example-turn-with-wrong-verification-fm-33","title":"Example Turn with Wrong Verification (FM-3.3)","text":"<pre><code>{\n  \"turn\": 8,\n  \"question_id\": 33102,\n  \"question\": \"Can you eat it?\",\n  \"answer\": true,\n  \"feasible_set_size_before\": 4,\n  \"feasible_set_size_after\": 2,\n  \"entropy_before\": 2.0,\n  \"entropy_after\": 1.0,\n  \"split_ratio\": 0.5,\n  \"branch_taken\": \"yes\",\n  \"branch_probability\": 0.5,\n  \"model_action\": \"guess\",\n  \"guess\": {\n    \"secret_index\": 42,\n    \"secret\": \"Apple\",\n    \"confidence\": 0.92,\n    \"verification_claim\": \"Based on the answers, it must be Apple because it's edible, found in nature, and commonly red.\"\n  },\n  \"guess_correct\": false,\n  \"prediction\": {\n    \"predicted_answer\": true,\n    \"confidence\": 0.85\n  }\n}\n</code></pre>"},{"location":"TURN_SCHEMA/#derived-metrics","title":"Derived Metrics","text":"<p>These can be computed from the turn fields:</p> Metric Formula Description Information Gain <code>entropy_before - entropy_after</code> Bits of information gained Elimination Ratio <code>1 - (size_after / size_before)</code> Proportion of items eliminated Split Balance <code>1 - abs(split_ratio - 0.5) * 2</code> How balanced the split is (1.0 = perfect) Surprise <code>-log2(branch_probability)</code> Surprisal of the taken branch"},{"location":"TURN_SCHEMA/#trajectory-type-patterns","title":"Trajectory Type Patterns","text":"<p>Different trajectory types have characteristic turn patterns:</p> Type Pattern Typical Split Ratios T1 Smooth halving ~0.5 throughout T2 Early collapse Extreme early, balanced late T3 Plateau Near-plateau, then balanced T4 Redundant loop Consecutive ~0.0 or ~1.0 T5 Multi-modal Skewed mid-game T6 Mismatch Balanced (mismatch in prediction) T7 Late shock Balanced early, extreme late T8 Wrong verification Balanced + wrong guess"},{"location":"archetypes/","title":"Trajectory Archetypes","text":"<p>The generator produces 8 distinct trajectory types (T1-T8), each designed to stress-test specific failure modes.</p>"},{"location":"archetypes/#overview","title":"Overview","text":"Type Name Entropy Pattern MAST Mode T1 Smooth halving 7\u21926\u21925\u21924\u21923\u21922\u21921\u21920 baseline T2 Early collapse 7\u21923\u21922\u2192...\u21920 FM-2.6 T3 Plateau 7\u21926.9\u21926.8\u2192...\u21924\u21922\u21920 FM-3.1 T4 Redundant loop 7\u21926.99\u21926.98\u2192... FM-1.3 T5 Multi-modal irregular FM-2.2 T6 Prediction mismatch varies FM-2.6 T7 Late shock 7\u21924\u21922\u21921\u21920.5\u21920 FM-3.1 T8 Wrong verification varies FM-3.3"},{"location":"archetypes/#generation-modes","title":"Generation Modes","text":""},{"location":"archetypes/#secret-first-t1-t6","title":"Secret-First (T1, T6)","text":"<ol> <li>Choose secret item</li> <li>Select questions matching target entropy curve</li> <li>Answers determined by secret</li> </ol> <p>Best for: Controlled entropy curves where the secret constrains answers.</p>"},{"location":"archetypes/#path-first-t2-t3-t4-t5-t7-t8","title":"Path-First (T2, T3, T4, T5, T7, T8)","text":"<ol> <li>Build question-answer sequence following constraints</li> <li>Sample secret from final feasible set</li> <li>Verify answer consistency</li> </ol> <p>Best for: Specific branch patterns (rare branches, plateaus) that require answer control.</p>"},{"location":"archetypes/#entropy-curves","title":"Entropy Curves","text":"<pre><code>T1 (baseline):     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  (smooth descent)\nT2 (early collapse): \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  (sharp drop, recovery)\nT3 (plateau):      \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  (flat, then drop)\nT4 (redundant):    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  (nearly flat)\nT5 (multi-modal):  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2588\u2588\u2591\u2591\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591  (irregular)\nT7 (late shock):   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591  (smooth, then sharp)\n</code></pre>"},{"location":"archetypes/#gate-validators","title":"Gate Validators","text":"<p>Each type has an automated validator:</p> <pre><code>python run.py validate outputs/ --show-failures\n</code></pre> Type Gate Constraint T1 All splits balanced (|p - 0.5| \u2264 0.15) T2 Rare branch in turns 1-3 AND after turn 3 T3 \u22653 consecutive low-IG turns, then resolution T4 \u22653 consecutive low-IG turns T5 Not all balanced + skewed mid-game T6 (none) T7 Rare branch in last 2 turns T8 Wrong guess + verification_claim"},{"location":"archetypes/t1/","title":"T1 - Smooth Halving","text":"<p>MAST Mode: baseline (no failure)</p> <p>Pattern: Consistent 50/50 splits, entropy decreases by ~1 bit per turn</p>"},{"location":"archetypes/t1/#description","title":"Description","text":"<p>T1 is the control trajectory - it represents ideal information-seeking behavior:</p> <ul> <li>Every question splits the feasible set roughly in half</li> <li>Entropy decreases smoothly: 7\u21926\u21925\u21924\u21923\u21922\u21921\u21920</li> <li>No wasted questions, no surprises</li> <li>Agent guesses correctly when |S|=1</li> </ul> <p>Use T1 as a baseline to compare against failure modes.</p>"},{"location":"archetypes/t1/#generation","title":"Generation","text":"<p>Mode: Secret-first</p> <pre><code>python run.py single --type T1\n</code></pre> <p>No special overlays required.</p>"},{"location":"archetypes/t1/#gate-validator","title":"Gate Validator","text":"<pre><code>def validate_t1_gate(trajectory):\n    for turn in trajectory.turns:\n        if turn.feasible_set_size_after &gt; 1:\n            # All splits must be balanced\n            if abs(turn.split_ratio - 0.5) &gt; 0.15:\n                return FAIL\n    return PASS\n</code></pre>"},{"location":"archetypes/t1/#example-trajectory","title":"Example Trajectory","text":"<p>Secret: Bear (index 5)</p> Turn Question Answer H |S| split 1 \"Is it alive?\" YES 6.0 64 0.50 2 \"Is it an animal?\" YES 5.0 32 0.50 3 \"Is it a mammal?\" YES 4.0 16 0.50 4 \"Is it larger than a dog?\" YES 3.0 8 0.50 5 \"Is it found in forests?\" YES 2.0 4 0.50 6 \"Is it a predator?\" YES 1.0 2 0.50 7 \"Is it a bear?\" YES 0.0 1 0.50"},{"location":"archetypes/t1/#entropy-curve","title":"Entropy Curve","text":"<pre><code>H (bits)\n7 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n6 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n5 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n4 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n3 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n2 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n1 \u2588\u2588\u2588\u2588\n0\n  T1  T2  T3  T4  T5  T6  T7\n</code></pre>"},{"location":"archetypes/t1/#why-no-failure-mode","title":"Why No Failure Mode","text":"<p>T1 exhibits:</p> <ul> <li>\u2705 Optimal question selection (max IG)</li> <li>\u2705 Calibrated predictions (confidence matches uncertainty)</li> <li>\u2705 Correct termination (guess at |S|=1)</li> <li>\u2705 No wasted effort</li> </ul>"},{"location":"archetypes/t1/#overlay-tags","title":"Overlay Tags","text":"<pre><code>{\n  \"overlay_tags\": [\"pred:calibrated_argmax\", \"term:rational\", \"term:guess_at_end\"],\n  \"target_mast_modes\": []\n}\n</code></pre>"},{"location":"archetypes/t2/","title":"T2 - Early Collapse","text":"<p>MAST Mode: FM-2.6 (Reasoning-action mismatch)</p> <p>Pattern: Sharp entropy drop early via rare branches</p>"},{"location":"archetypes/t2/#description","title":"Description","text":"<p>T2 demonstrates prediction-belief mismatch:</p> <ul> <li>Early questions have extreme splits (p \u2248 0.1 or 0.9)</li> <li>The oracle takes the unlikely branch, causing rapid collapse</li> <li>A calibrated predictor predicts the majority answer</li> <li>The mismatch between prediction and reality exposes miscalibration</li> </ul>"},{"location":"archetypes/t2/#generation","title":"Generation","text":"<p>Mode: Path-first</p> <pre><code>python run.py single --type T2\n</code></pre>"},{"location":"archetypes/t2/#gate-validator","title":"Gate Validator","text":"<pre><code>def validate_t2_gate(trajectory):\n    early_rare = None\n    later_rare = None\n\n    for turn in trajectory.turns:\n        if turn.branch_probability &lt;= 0.25:\n            if turn.turn &lt;= 3:\n                early_rare = turn.turn\n            elif early_rare and turn.turn &gt;= 4:\n                later_rare = turn.turn\n                break\n\n    return PASS if (early_rare and later_rare) else FAIL\n</code></pre>"},{"location":"archetypes/t2/#example-trajectory","title":"Example Trajectory","text":"<p>Secret: Tiger (index 112)</p> Turn Question Answer H |S| p_branch 1 \"Is it man-made?\" NO 6.0 64 0.12 2 \"Is it microscopic?\" NO 5.0 32 0.15 3 \"Is it a plant?\" NO 4.5 24 0.25 4 \"Is it a mammal?\" YES 3.5 12 0.50 5 \"Is it domesticated?\" NO 2.5 6 0.17 6 \"Is it a big cat?\" YES 0.0 1 0.33"},{"location":"archetypes/t2/#entropy-curve","title":"Entropy Curve","text":"<pre><code>H: 7 \u2192 4 \u2192 3 \u2192 2 \u2192 1 \u2192 0\n      \u2193\n   sharp early drop from rare branches\n</code></pre>"},{"location":"archetypes/t2/#why-fm-26","title":"Why FM-2.6","text":"<p>At turn 1:</p> <ul> <li>split_ratio = 0.88 (88% would answer YES)</li> <li>Calibrated prediction = YES (majority)</li> <li>Oracle answer = NO (minority)</li> <li>Mismatch = prediction \u2260 reality</li> </ul> <p>The agent's stated belief (YES is likely) contradicts the observed outcome.</p>"},{"location":"archetypes/t2/#overlay-tags","title":"Overlay Tags","text":"<pre><code>{\n  \"overlay_tags\": [\"pred:calibrated_argmax\", \"term:rational\", \"term:guess_at_end\"],\n  \"target_mast_modes\": [\"FM-2.6\"]\n}\n</code></pre>"},{"location":"archetypes/t3/","title":"T3 - Plateau","text":"<p>MAST Mode: FM-3.1 (Premature termination) or FM-1.5 (Unaware of termination)</p> <p>Pattern: Long stretch of low-IG questions, then forced resolution</p>"},{"location":"archetypes/t3/#description","title":"Description","text":"<p>T3 creates a plateau in the entropy curve:</p> <ul> <li>Multiple consecutive questions with minimal information gain</li> <li>Entropy stays nearly flat (\u0394H \u2248 0 per turn)</li> <li>Eventually a high-IG question forces resolution</li> <li>Tests whether agent recognizes \"stuck\" states</li> </ul>"},{"location":"archetypes/t3/#generation","title":"Generation","text":"<p>Mode: Path-first</p> <pre><code># For FM-3.1 (premature stop during plateau)\npython run.py single --type T3 --termination premature_stop\n\n# For FM-1.5 (continues past when should stop)\npython run.py single --type T3 --termination unaware\n</code></pre>"},{"location":"archetypes/t3/#gate-validator","title":"Gate Validator","text":"<pre><code>def validate_t3_gate(trajectory):\n    # Need \u22653 consecutive low-IG turns\n    max_plateau = 0\n    current_plateau = 0\n\n    for turn in trajectory.turns:\n        delta_h = turn.entropy_before - turn.entropy_after\n        if delta_h &lt;= 0.15:\n            current_plateau += 1\n            max_plateau = max(max_plateau, current_plateau)\n        else:\n            current_plateau = 0\n\n    # Also need resolution phase\n    has_resolution = any(\n        abs(t.split_ratio - 0.5) &lt;= 0.15\n        for t in trajectory.turns\n    )\n\n    return PASS if (max_plateau &gt;= 3 and has_resolution) else FAIL\n</code></pre>"},{"location":"archetypes/t3/#example-trajectory","title":"Example Trajectory","text":"<p>Secret: Lamp (index 62)</p> Turn Question Answer H \u0394H |S| 1 \"Is it blue?\" NO 6.99 0.01 127 2 \"Is it round?\" NO 6.98 0.01 126 3 \"Is it soft?\" NO 6.97 0.01 125 4 \"Is it edible?\" NO 6.96 0.01 124 5 \"Is it electronic?\" YES 5.0 1.96 32 ... ... ... ... ... ... 10 \"Is it a lamp?\" YES 0.0 1.0 1"},{"location":"archetypes/t3/#entropy-curve","title":"Entropy Curve","text":"<pre><code>H (bits)\n7 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n7 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  \u2190 plateau\n7 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n7 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n5 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n3 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n1 \u2588\u2588\u2588\u2588\n0\n</code></pre>"},{"location":"archetypes/t3/#why-fm-31-fm-15","title":"Why FM-3.1 / FM-1.5","text":"<p>FM-3.1 (Premature termination): With <code>premature_stop</code> overlay, the agent stops during the plateau, giving up before finding good questions.</p> <p>FM-1.5 (Unaware of termination): With <code>unaware</code> overlay, the agent continues asking low-IG questions even when |S| is small enough to guess.</p>"},{"location":"archetypes/t3/#overlay-tags","title":"Overlay Tags","text":"<pre><code>{\n  \"overlay_tags\": [\"pred:calibrated_argmax\", \"term:premature_stop\"],\n  \"target_mast_modes\": [\"FM-3.1\"]\n}\n</code></pre>"},{"location":"archetypes/t4/","title":"T4 - Redundant Loop","text":"<p>MAST Mode: FM-1.3 (Step repetition)</p> <p>Pattern: Consecutive questions with near-zero information gain</p>"},{"location":"archetypes/t4/#description","title":"Description","text":"<p>T4 demonstrates wasted effort:</p> <ul> <li>Multiple consecutive questions eliminate only 1 item each</li> <li>Entropy decreases by ~0.01 bits per turn (vs ~1 bit optimal)</li> <li>Agent asks \"Is it X?\" style questions instead of category splits</li> <li>Represents inefficient search strategy</li> </ul>"},{"location":"archetypes/t4/#generation","title":"Generation","text":"<p>Mode: Path-first</p> <pre><code>python run.py single --type T4\n</code></pre> <p>No special overlay required - the world itself creates the failure.</p>"},{"location":"archetypes/t4/#gate-validator","title":"Gate Validator","text":"<pre><code>def validate_t4_gate(trajectory):\n    # Need \u22653 consecutive low-IG turns\n    consecutive_low_ig = 0\n    max_consecutive = 0\n\n    for turn in trajectory.turns:\n        delta_h = turn.entropy_before - turn.entropy_after\n        if delta_h &lt;= 0.15:\n            consecutive_low_ig += 1\n            max_consecutive = max(max_consecutive, consecutive_low_ig)\n        else:\n            consecutive_low_ig = 0\n\n    return PASS if max_consecutive &gt;= 3 else FAIL\n</code></pre>"},{"location":"archetypes/t4/#example-trajectory","title":"Example Trajectory","text":"<p>Secret: Train (index 119)</p> Turn Question Answer H \u0394H |S| 1 \"Is it a board game?\" NO 6.99 0.01 127 2 \"Is it a bracelet?\" NO 6.98 0.01 126 3 \"Is it a hat?\" NO 6.97 0.01 125 4 \"Is it a lake?\" NO 6.95 0.02 124 5 \"Is it a celestial object?\" NO 6.94 0.01 123 6 \"Is it a tropical flower?\" NO 6.93 0.01 122 7 \"Is it used for cutting?\" NO 6.92 0.01 121 8 \"Usually found indoors?\" YES 5.93 0.99 61"},{"location":"archetypes/t4/#entropy-curve","title":"Entropy Curve","text":"<pre><code>H (bits)\n7.00 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n6.99 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n6.98 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n6.97 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  \u2190 wasted turns\n6.96 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n6.95 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n5.93 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n</code></pre>"},{"location":"archetypes/t4/#why-fm-13","title":"Why FM-1.3","text":"<p>Each low-IG question is essentially repeating the same strategy:</p> <ul> <li>Asking about specific items (split \u2248 1/128)</li> <li>Instead of asking about categories (split \u2248 0.5)</li> <li>Information gain: 0.01 bits vs 1.0 bits possible</li> </ul> <p>This is analogous to step repetition in other tasks - doing the same ineffective thing repeatedly.</p>"},{"location":"archetypes/t4/#training-signal","title":"Training Signal","text":"<pre><code># Reward shaping for T4\nfor turn in trajectory.turns:\n    ig = turn.entropy_before - turn.entropy_after\n    reward = ig - 0.5  # Penalize below-average IG\n\n# Turns 1-7: reward \u2248 -0.49 each (bad)\n# Turn 8: reward \u2248 +0.49 (good)\n</code></pre>"},{"location":"archetypes/t4/#overlay-tags","title":"Overlay Tags","text":"<pre><code>{\n  \"overlay_tags\": [\"pred:calibrated_argmax\", \"term:rational\", \"term:guess_at_budget\"],\n  \"target_mast_modes\": [\"FM-1.3\"]\n}\n</code></pre> <p>Note: <code>term:guess_at_budget</code> because the trajectory often hits turn limit before |S|=1.</p>"},{"location":"archetypes/t5/","title":"T5 - Multi-modal","text":"<p>MAST Mode: FM-2.2 (Multi-modal ambiguity)</p> <p>Pattern: Skewed splits in mid-game create sustained ambiguity</p>"},{"location":"archetypes/t5/#description","title":"Description","text":"<p>T5 demonstrates multi-modal uncertainty:</p> <ul> <li>Unlike T1's smooth halving, T5 has irregular entropy descent</li> <li>Mid-game region (|S| \u2208 [8, 32]) has skewed splits</li> <li>Multiple plausible hypotheses remain viable longer</li> <li>Tests whether agent handles non-uniform belief distributions</li> </ul>"},{"location":"archetypes/t5/#generation","title":"Generation","text":"<p>Mode: Path-first</p> <pre><code>python run.py single --type T5\n</code></pre> <p>No special overlay required - the world itself creates the ambiguity.</p>"},{"location":"archetypes/t5/#gate-validator","title":"Gate Validator","text":"<pre><code>def validate_t5_gate(trajectory):\n    balanced_count = 0\n    skewed_mid_count = 0\n\n    for turn in trajectory.turns:\n        is_balanced = abs(turn.split_ratio - 0.5) &lt;= 0.15\n        is_mid_game = 8 &lt;= turn.feasible_set_size_before &lt;= 32\n\n        if is_balanced:\n            balanced_count += 1\n        if is_mid_game and not is_balanced:\n            skewed_mid_count += 1\n\n    # Fail if all balanced (that's T1)\n    if balanced_count == len(trajectory.turns):\n        return FAIL\n\n    # Require at least one skewed mid-game turn\n    return PASS if skewed_mid_count &gt; 0 else FAIL\n</code></pre>"},{"location":"archetypes/t5/#example-trajectory","title":"Example Trajectory","text":"<p>Secret: Guitar (index 48)</p> Turn Question Answer H |S| split 1 \"Is it alive?\" NO 6.0 64 0.50 2 \"Is it electronic?\" NO 5.0 32 0.50 3 \"Is it used outdoors?\" NO 4.2 18 0.44 4 \"Is it made of wood?\" YES 3.5 11 0.61 5 \"Is it furniture?\" NO 2.8 7 0.36 6 \"Is it musical?\" YES 1.6 3 0.43 7 \"Has strings?\" YES 0.0 1 0.67"},{"location":"archetypes/t5/#entropy-curve","title":"Entropy Curve","text":"<pre><code>H (bits)\n7 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n6 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n5 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n4 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588      \u2190 irregular descent\n3 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n2 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n1 \u2588\u2588\u2588\u2588\n0\n</code></pre>"},{"location":"archetypes/t5/#why-fm-22","title":"Why FM-2.2","text":"<p>In mid-game, the belief distribution is not uniform:</p> <ul> <li>Some items are more likely than others</li> <li>But multiple items remain plausible</li> <li>Agent must maintain multi-modal beliefs</li> </ul> <p>Example at turn 5: <pre><code>Feasible: {Guitar, Violin, Cello, Drum, Flute, Piano, Harp}\np(Guitar) \u2248 0.14, p(Violin) \u2248 0.14, ...\n\nNot: \"It's probably Guitar\" (overconfident)\nNot: \"All equally likely\" (ignoring question structure)\n</code></pre></p>"},{"location":"archetypes/t5/#training-signal","title":"Training Signal","text":"<p>For T5, a good reward penalizes:</p> <ul> <li>Committing to MAP too early (when distribution is multi-modal)</li> <li>Treating uniform as calibrated (when it's not)</li> </ul> <pre><code># Brier score penalty for miscalibration\nbrier = sum((p_i - indicator_i)**2 for i in items)\nreward = -brier\n</code></pre>"},{"location":"archetypes/t5/#overlay-tags","title":"Overlay Tags","text":"<pre><code>{\n  \"overlay_tags\": [\"pred:calibrated_argmax\", \"term:rational\", \"term:guess_at_end\"],\n  \"target_mast_modes\": [\"FM-2.2\"]\n}\n</code></pre>"},{"location":"archetypes/t6/","title":"T6 - Prediction Mismatch","text":"<p>MAST Mode: FM-2.6 (Reasoning-action mismatch)</p> <p>Pattern: Calibrated predictions systematically wrong due to unlikely branches</p>"},{"location":"archetypes/t6/#description","title":"Description","text":"<p>T6 demonstrates calibration failure:</p> <ul> <li>Questions have split_ratio \u2265 0.5 (majority would answer YES)</li> <li>Secret is chosen to answer NO (minority branch)</li> <li>Calibrated argmax predicts YES, oracle says NO</li> <li>Repeated mismatches expose the gap between belief and reality</li> </ul>"},{"location":"archetypes/t6/#generation","title":"Generation","text":"<p>Mode: Secret-first</p> <pre><code>python run.py single --type T6\n</code></pre> <p>The secret-first mode selects a secret that takes minority branches.</p>"},{"location":"archetypes/t6/#gate-validator","title":"Gate Validator","text":"<pre><code>def validate_t6_gate(trajectory):\n    # No specific world constraints - always passes\n    # The mismatch is created by secret selection\n    return PASS\n</code></pre>"},{"location":"archetypes/t6/#example-trajectory","title":"Example Trajectory","text":"<p>Secret: Anchor (index 2)</p> Turn Question Answer split Prediction Match? 1 \"Is it alive?\" NO 0.70 YES \u274c 2 \"Is it used indoors?\" NO 0.65 YES \u274c 3 \"Is it colorful?\" NO 0.55 YES \u274c 4 \"Is it made of metal?\" YES 0.52 YES \u2705 5 \"Is it used on boats?\" YES 0.50 YES \u2705 6 \"Is it an anchor?\" YES 1.0 YES \u2705"},{"location":"archetypes/t6/#the-mismatch-pattern","title":"The Mismatch Pattern","text":"<pre><code>Turn 1: p_yes=0.70, predict=YES, actual=NO  \u2192 MISMATCH\nTurn 2: p_yes=0.65, predict=YES, actual=NO  \u2192 MISMATCH\nTurn 3: p_yes=0.55, predict=YES, actual=NO  \u2192 MISMATCH\n</code></pre> <p>The calibrated predictor is doing the \"right\" thing (predicting majority), but the world is adversarial.</p>"},{"location":"archetypes/t6/#why-fm-26","title":"Why FM-2.6","text":"<p>Reasoning: \"70% of items would answer YES, so I predict YES\"</p> <p>Action outcome: The oracle answered NO</p> <p>This is a reasoning-action mismatch - the agent's stated reasoning led to an incorrect prediction, not because the reasoning was flawed, but because the world selected against it.</p>"},{"location":"archetypes/t6/#training-implications","title":"Training Implications","text":"<p>T6 teaches:</p> <ol> <li>Calibration \u2260 accuracy - Being well-calibrated means being wrong 30% of the time when p=0.70</li> <li>Epistemic humility - Majority vote doesn't guarantee correctness</li> <li>Update on evidence - After seeing NO, update beliefs appropriately</li> </ol>"},{"location":"archetypes/t6/#difference-from-t2","title":"Difference from T2","text":"Aspect T2 T6 Generation Path-first Secret-first Branch rarity Very rare (p &lt; 0.15) Moderately rare (0.3-0.5) Entropy drop Sharp Gradual Mismatch frequency Sporadic Consistent"},{"location":"archetypes/t6/#overlay-tags","title":"Overlay Tags","text":"<pre><code>{\n  \"overlay_tags\": [\"pred:calibrated_argmax\", \"term:rational\", \"term:guess_at_end\"],\n  \"target_mast_modes\": [\"FM-2.6\"]\n}\n</code></pre>"},{"location":"archetypes/t7/","title":"T7 - Late Shock","text":"<p>MAST Mode: FM-3.1 (Premature termination)</p> <p>Pattern: Smooth descent then rare branch at the end</p>"},{"location":"archetypes/t7/#description","title":"Description","text":"<p>T7 creates a confidence collapse:</p> <ul> <li>Early/mid-game proceeds smoothly with balanced splits</li> <li>Agent builds confidence as entropy decreases</li> <li>Late-game rare branch causes unexpected large entropy drop</li> <li>Tests whether agent handles sudden uncertainty shifts</li> </ul>"},{"location":"archetypes/t7/#generation","title":"Generation","text":"<p>Mode: Path-first</p> <pre><code># For FM-3.1 (premature stop before shock)\npython run.py single --type T7 --termination premature_stop\n</code></pre>"},{"location":"archetypes/t7/#gate-validator","title":"Gate Validator","text":"<pre><code>def validate_t7_gate(trajectory):\n    # Check last 2 turns for rare branch\n    for turn in trajectory.turns[-2:]:\n        if turn.branch_probability &lt;= 0.25:\n            return PASS\n    return FAIL\n</code></pre>"},{"location":"archetypes/t7/#example-trajectory","title":"Example Trajectory","text":"<p>Secret: Canvas (index 21)</p> Turn Question Answer H |S| p_branch 1 \"Used on flat surface?\" YES 6.4 83 0.65 2 \"Used in classroom?\" YES 5.8 54 0.65 3 \"Used as d\u00e9cor?\" YES 5.1 35 0.65 4 \"Take when traveling?\" YES 4.5 23 0.66 5 \"Is it reusable?\" YES 3.9 15 0.65 6 \"Used professionally?\" YES 3.3 10 0.67 7 \"For communication?\" YES 2.8 7 0.70 8 \"Can you play with it?\" NO 0.0 1 0.14"},{"location":"archetypes/t7/#entropy-curve","title":"Entropy Curve","text":"<pre><code>H (bits)\n7 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n6 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n5 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n4 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n3 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n2 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n1 \u2588\u2588\u2588\u2588          \u2190 smooth descent\n0 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  \u2190 sudden drop (shock)\n</code></pre>"},{"location":"archetypes/t7/#why-fm-31","title":"Why FM-3.1","text":"<p>With <code>premature_stop</code> overlay:</p> <p>Turn 3 (H=5.1 bits): <pre><code>{\n  \"model_action\": \"stop\",\n  \"stop_reason\": \"Premature stop at entropy 5.13 bits, |S|=35\",\n  \"stop_accepted\": false\n}\n</code></pre></p> <p>The agent attempts to stop mid-game, thinking progress is going well. The environment rejects the stop, and the game continues.</p>"},{"location":"archetypes/t7/#the-shock-moment","title":"The \"Shock\" Moment","text":"<p>At turn 8:</p> <ul> <li>Before: H = 2.8 bits, |S| = 7</li> <li>split_ratio = 0.86 (86% would answer YES)</li> <li>Answer: NO (rare branch, p = 0.14)</li> <li>After: H = 0 bits, |S| = 1</li> </ul> <p>The rare NO answer eliminates 6 of 7 remaining items in one turn.</p>"},{"location":"archetypes/t7/#training-signal","title":"Training Signal","text":"<pre><code># Penalize premature stop\nif turn.model_action == \"stop\" and turn.entropy_after &gt; 1.0:\n    reward = -turn.entropy_after  # More entropy = worse\n\n# Turn 3 stop attempt: reward = -5.1 (very bad)\n</code></pre>"},{"location":"archetypes/t7/#overlay-tags","title":"Overlay Tags","text":"<pre><code>{\n  \"overlay_tags\": [\"pred:calibrated_argmax\", \"term:premature_stop\", \"term:guess_at_end\"],\n  \"target_mast_modes\": [\"FM-3.1\"]\n}\n</code></pre>"},{"location":"archetypes/t8/","title":"T8 - Wrong Verification","text":"<p>MAST Mode: FM-3.3 (Incorrect Verification)</p> <p>Pattern: Agent makes an incorrect guess with a false verification claim</p>"},{"location":"archetypes/t8/#description","title":"Description","text":"<p>T8 trajectories demonstrate incorrect verification - the agent:</p> <ol> <li>Commits to a guess while multiple items remain feasible</li> <li>Provides a verification claim that (falsely) asserts consistency</li> <li>Gets rejected (<code>stop_accepted=false</code>)</li> <li>Continues and eventually finds the correct answer</li> </ol> <p>This is the canonical example for RL training because it contains both failure and recovery.</p>"},{"location":"archetypes/t8/#generation","title":"Generation","text":"<p>Mode: Path-first</p> <p>Required overlay: <code>--termination wrong_guess</code></p> <pre><code>python run.py single --type T8 --termination wrong_guess\n</code></pre>"},{"location":"archetypes/t8/#gate-validator","title":"Gate Validator","text":"<pre><code>def validate_t8_gate(trajectory):\n    # Must have wrong guess with verification claim\n    for turn in trajectory.turns:\n        if turn.guess and not turn.guess_correct:\n            if turn.guess.verification_claim:\n                return PASS\n    return FAIL\n</code></pre>"},{"location":"archetypes/t8/#example-trajectory","title":"Example Trajectory","text":"<p>Secret: Horse (index 56)</p> Turn Question Answer H |S| Action 1 \"leisure activities?\" YES 6.0 64 continue 2 \"professional purposes?\" YES 5.0 32 continue 3 \"found in store?\" NO 2.3 5 continue 4 \"used for decoration?\" NO 1.6 3 GUESS (wrong) 5 \"smaller than car?\" YES 1.0 2 continue 6 \"inanimate object?\" NO 0.0 1 GUESS (correct)"},{"location":"archetypes/t8/#turn-4-detail","title":"Turn 4 Detail","text":"<pre><code>{\n  \"turn\": 4,\n  \"entropy_after\": 1.58,\n  \"model_action\": \"guess\",\n  \"guess\": {\n    \"secret\": \"Watermelon\",\n    \"confidence\": 0.9,\n    \"verification_claim\": \"The secret must be 'Watermelon' because\n      the answer to 'Is it used for leisure activities?' was Yes,\n      which is consistent with 'Watermelon'.\"\n  },\n  \"guess_correct\": false,\n  \"stop_accepted\": false\n}\n</code></pre>"},{"location":"archetypes/t8/#why-this-is-fm-33","title":"Why This is FM-3.3","text":"<p>The verification claim is incorrect because:</p> <ol> <li>\"Consistent with Watermelon\" is true but insufficient</li> <li>Horse and 1 other item are also consistent</li> <li>The agent conflated consistency with uniqueness</li> </ol>"},{"location":"archetypes/t8/#training-signal","title":"Training Signal","text":"Turn State Action Reward Lesson 4 H=1.6 GUESS -0.9 Don't guess at H&gt;0 with high confidence 6 H=0 GUESS +1.0 Guess when H=0"},{"location":"archetypes/t8/#overlay-tags","title":"Overlay Tags","text":"<pre><code>{\n  \"overlay_tags\": [\n    \"pred:calibrated_argmax\",\n    \"term:wrong_guess\",\n    \"term:guess_at_end\",\n    \"verify:claim_present\"\n  ],\n  \"target_mast_modes\": [\"FM-3.3\"]\n}\n</code></pre>"},{"location":"mast/","title":"MAST Failure Modes","text":"<p>MAST (Model Alignment and Safety Taxonomy) categorizes how AI agents fail during multi-step tasks.</p>"},{"location":"mast/#overview","title":"Overview","text":"Category Focus Failure Type FM-1.x Specification Wrong actions FM-2.x Belief Miscalibration FM-3.x Verification Bad termination"},{"location":"mast/#failure-modes-in-this-toolkit","title":"Failure Modes in This Toolkit","text":""},{"location":"mast/#fm-1-specification-failures","title":"FM-1: Specification Failures","text":"Mode Description Trajectory FM-1.1 Disobey task specification T2, T8 FM-1.3 Step repetition / redundancy T4 FM-1.5 Unaware of termination conditions T3"},{"location":"mast/#fm-2-belief-failures","title":"FM-2: Belief Failures","text":"Mode Description Trajectory FM-2.2 Multi-modal ambiguity T5 FM-2.6 Reasoning-action mismatch T2, T6"},{"location":"mast/#fm-3-verification-failures","title":"FM-3: Verification Failures","text":"Mode Description Trajectory FM-3.1 Premature termination T3, T7 FM-3.2 Incomplete verification T7 FM-3.3 Incorrect verification T8"},{"location":"mast/#mapping-trajectories-to-modes","title":"Mapping Trajectories to Modes","text":"<pre><code>T1 (baseline)     \u2192 no failure mode (control)\nT2 (collapse)     \u2192 FM-2.6 (prediction \u2260 reality)\nT3 (plateau)      \u2192 FM-3.1 (premature stop) or FM-1.5 (unaware)\nT4 (redundant)    \u2192 FM-1.3 (wasted questions)\nT5 (multi-modal)  \u2192 FM-2.2 (ambiguous state)\nT6 (mismatch)     \u2192 FM-2.6 (calibration error)\nT7 (late shock)   \u2192 FM-3.1 (confidence collapse)\nT8 (wrong verify) \u2192 FM-3.3 (false verification claim)\n</code></pre>"},{"location":"mast/#overlay-requirements","title":"Overlay Requirements","text":"<p>Some failure modes require specific overlays:</p> Mode Required Overlay Tag FM-3.1 <code>premature_stop</code> <code>term:premature_stop</code> FM-3.3 <code>wrong_guess</code> <code>term:wrong_guess</code> + <code>verify:claim_present</code> FM-1.5 <code>unaware</code> <code>term:unaware</code> <p>World-only modes (no overlay needed):</p> <ul> <li>FM-1.3 (T4 world enforces low-IG)</li> <li>FM-2.2 (T5 world enforces ambiguity)</li> <li>FM-2.6 (T2/T6 world creates mismatch opportunity)</li> </ul>"},{"location":"mast/#deriving-modes-from-trajectories","title":"Deriving Modes from Trajectories","text":"<p>The <code>target_mast_modes</code> field is derived automatically:</p> <pre><code>def derive_mast_modes(trajectory_type: str, overlay_tags: list[str]) -&gt; list[str]:\n    modes = []\n\n    # World-only modes\n    if trajectory_type == \"T4\":\n        modes.append(\"FM-1.3\")\n    if trajectory_type == \"T5\":\n        modes.append(\"FM-2.2\")\n\n    # Overlay-dependent modes\n    if trajectory_type in (\"T2\", \"T6\") and \"pred:calibrated_argmax\" in overlay_tags:\n        modes.append(\"FM-2.6\")\n    if trajectory_type in (\"T3\", \"T7\") and \"term:premature_stop\" in overlay_tags:\n        modes.append(\"FM-3.1\")\n    if trajectory_type == \"T8\" and \"term:wrong_guess\" in overlay_tags:\n        modes.append(\"FM-3.3\")\n\n    return modes\n</code></pre>"},{"location":"mast/fm1/","title":"FM-1: Specification Failures","text":"<p>Specification failures occur when the agent takes actions that violate task requirements.</p>"},{"location":"mast/fm1/#fm-11-disobey-task-specification","title":"FM-1.1: Disobey Task Specification","text":"<p>Definition: Agent takes an action explicitly forbidden by the task.</p> <p>In 20 Questions: Guessing an item that is not in the feasible set.</p> <p>Trajectories: T2, T8 (with <code>wrong_guess</code> overlay)</p>"},{"location":"mast/fm1/#example","title":"Example","text":"<pre><code>{\n  \"turn\": 4,\n  \"feasible_set\": [\"Horse\", \"Cow\", \"Dog\"],\n  \"guess\": {\n    \"secret\": \"Watermelon\",  // NOT in feasible set\n    \"confidence\": 0.9\n  },\n  \"guess_correct\": false\n}\n</code></pre>"},{"location":"mast/fm1/#detection","title":"Detection","text":"<pre><code>def detect_fm11(trajectory):\n    for turn in trajectory.turns:\n        if turn.guess and not turn.guess_correct:\n            # Wrong guess = potential FM-1.1\n            return True\n    return False\n</code></pre>"},{"location":"mast/fm1/#fm-13-step-repetition","title":"FM-1.3: Step Repetition","text":"<p>Definition: Agent repeats the same ineffective action multiple times.</p> <p>In 20 Questions: Asking consecutive low-information-gain questions.</p> <p>Trajectories: T4</p>"},{"location":"mast/fm1/#example_1","title":"Example","text":"<pre><code>Turn 1: \"Is it a hat?\"      \u2192 IG = 0.01 bits\nTurn 2: \"Is it a bracelet?\" \u2192 IG = 0.01 bits\nTurn 3: \"Is it a shoe?\"     \u2192 IG = 0.01 bits\n</code></pre> <p>Each question only eliminates 1 item when ~64 could be eliminated with a balanced question.</p>"},{"location":"mast/fm1/#detection_1","title":"Detection","text":"<pre><code>def detect_fm13(trajectory):\n    low_ig_streak = 0\n    for turn in trajectory.turns:\n        ig = turn.entropy_before - turn.entropy_after\n        if ig &lt; 0.2:\n            low_ig_streak += 1\n        else:\n            low_ig_streak = 0\n        if low_ig_streak &gt;= 3:\n            return True\n    return False\n</code></pre>"},{"location":"mast/fm1/#fm-15-unaware-of-termination-conditions","title":"FM-1.5: Unaware of Termination Conditions","text":"<p>Definition: Agent continues working past when it should stop.</p> <p>In 20 Questions: Asking more questions when |S| = 1.</p> <p>Trajectories: T3 (with <code>unaware</code> overlay)</p>"},{"location":"mast/fm1/#example_2","title":"Example","text":"<pre><code>Turn 8: |S| = 2, action = \"ask\"  \u2190 reasonable\nTurn 9: |S| = 1, action = \"ask\"  \u2190 SHOULD GUESS\nTurn 10: |S| = 1, action = \"ask\" \u2190 FM-1.5\nTurn 11: |S| = 1, action = \"guess\" \u2190 finally\n</code></pre>"},{"location":"mast/fm1/#detection_2","title":"Detection","text":"<pre><code>def detect_fm15(trajectory):\n    for turn in trajectory.turns:\n        if turn.feasible_set_size_before == 1:\n            if turn.model_action == \"continue\":\n                return True\n    return False\n</code></pre>"},{"location":"mast/fm1/#summary-table","title":"Summary Table","text":"Mode Failure Detection Signal Trajectory FM-1.1 Wrong action <code>guess_correct=false</code> T2, T8 FM-1.3 Repeated waste IG &lt; 0.2 for 3+ turns T4 FM-1.5 Over-continuing action=\"ask\" when |S|=1 T3"},{"location":"mast/fm2/","title":"FM-2: Belief Failures","text":"<p>Belief failures occur when the agent's internal beliefs are miscalibrated or inconsistent.</p>"},{"location":"mast/fm2/#fm-22-multi-modal-ambiguity","title":"FM-2.2: Multi-modal Ambiguity","text":"<p>Definition: Agent fails to maintain appropriate uncertainty over multiple hypotheses.</p> <p>In 20 Questions: Collapsing to a single hypothesis too early when multiple items remain equally plausible.</p> <p>Trajectories: T5</p>"},{"location":"mast/fm2/#example","title":"Example","text":"<p>At turn 5 with |S| = 7:</p> <pre><code>Feasible: {Guitar, Violin, Cello, Drum, Flute, Piano, Harp}\n\nBAD (over-confident):\n  \"I'm 80% sure it's Guitar\"\n\nGOOD (multi-modal):\n  \"Each of the 7 instruments is roughly equally likely (14% each)\"\n</code></pre>"},{"location":"mast/fm2/#the-problem","title":"The Problem","text":"<p>When the feasible set contains multiple items with similar likelihoods, the agent should:</p> <ol> <li>Maintain a distribution over items (not point estimate)</li> <li>Acknowledge uncertainty in predictions</li> <li>Continue asking distinguishing questions</li> </ol>"},{"location":"mast/fm2/#detection","title":"Detection","text":"<pre><code>def detect_fm22(trajectory):\n    for turn in trajectory.turns:\n        # Mid-game with multiple items\n        if 4 &lt;= turn.feasible_set_size_after &lt;= 16:\n            # Check if prediction confidence is inappropriately high\n            if turn.prediction and turn.prediction.confidence &gt; 0.8:\n                # High confidence with many items = FM-2.2\n                return True\n    return False\n</code></pre>"},{"location":"mast/fm2/#fm-26-reasoning-action-mismatch","title":"FM-2.6: Reasoning-Action Mismatch","text":"<p>Definition: Agent's stated reasoning contradicts the action outcome.</p> <p>In 20 Questions: Predicting YES (based on majority) when the oracle answers NO.</p> <p>Trajectories: T2, T6</p>"},{"location":"mast/fm2/#example_1","title":"Example","text":"<pre><code>{\n  \"turn\": 1,\n  \"question\": \"Is it alive?\",\n  \"split_ratio\": 0.70,\n  \"prediction\": {\n    \"predicted_answer\": true,   // \"70% would say YES, so I predict YES\"\n    \"confidence\": 0.40\n  },\n  \"answer\": false               // Oracle says NO\n}\n</code></pre> <p>Reasoning: \"Most items are alive, so the answer is probably YES\"</p> <p>Reality: The secret is not alive</p>"},{"location":"mast/fm2/#why-this-happens","title":"Why This Happens","text":"<p>The mismatch isn't necessarily a \"bug\" - a well-calibrated predictor should sometimes be wrong. The issue is when:</p> <ol> <li>The agent claims certainty it doesn't have</li> <li>The agent fails to update beliefs after the mismatch</li> <li>The agent doesn't recognize that its predictions are systematically biased</li> </ol>"},{"location":"mast/fm2/#detection_1","title":"Detection","text":"<pre><code>def detect_fm26(trajectory):\n    mismatch_count = 0\n    for turn in trajectory.turns:\n        if turn.prediction:\n            predicted = turn.prediction.predicted_answer\n            actual = turn.answer\n            if predicted != actual:\n                mismatch_count += 1\n    # Multiple mismatches indicate systematic issue\n    return mismatch_count &gt;= 3\n</code></pre>"},{"location":"mast/fm2/#summary-table","title":"Summary Table","text":"Mode Failure Detection Signal Trajectory FM-2.2 Over-commitment High confidence with |S| &gt; 4 T5 FM-2.6 Predict \u2260 Actual prediction.answer \u2260 turn.answer T2, T6"},{"location":"mast/fm2/#training-implications","title":"Training Implications","text":"<p>For FM-2 failures, the reward should penalize:</p> <ol> <li>Overconfidence: Confidence exceeds 1/|S|</li> <li>Brier score: (predicted_prob - actual)\u00b2</li> <li>Calibration error: Mean difference between confidence and accuracy</li> </ol>"},{"location":"mast/fm3/","title":"FM-3: Verification Failures","text":"<p>Verification failures occur when the agent incorrectly decides to stop or validates its answer incorrectly.</p>"},{"location":"mast/fm3/#fm-31-premature-termination","title":"FM-3.1: Premature Termination","text":"<p>Definition: Agent stops before completing the task.</p> <p>In 20 Questions: Stopping or guessing when entropy is still high (|S| &gt; 1).</p> <p>Trajectories: T3, T7 (with <code>premature_stop</code> overlay)</p>"},{"location":"mast/fm3/#example","title":"Example","text":"<pre><code>{\n  \"turn\": 3,\n  \"entropy_after\": 5.13,\n  \"feasible_set_size_after\": 35,\n  \"model_action\": \"stop\",\n  \"stop_reason\": \"Premature stop at entropy 5.13 bits, |S|=35\",\n  \"stop_accepted\": false\n}\n</code></pre> <p>The agent attempts to stop when 35 items remain. The environment rejects this.</p>"},{"location":"mast/fm3/#why-this-happens","title":"Why This Happens","text":"<ol> <li>Impatience: Agent wants to finish quickly</li> <li>Misestimation: Agent thinks it has enough information</li> <li>Plateau fatigue: Agent gives up during low-IG streaks (T3)</li> </ol>"},{"location":"mast/fm3/#detection","title":"Detection","text":"<pre><code>def detect_fm31(trajectory):\n    for turn in trajectory.turns:\n        if turn.model_action in (\"stop\", \"guess\"):\n            if turn.entropy_after &gt; 1.0:  # More than 1 bit remaining\n                return True\n    return False\n</code></pre>"},{"location":"mast/fm3/#fm-32-incomplete-verification","title":"FM-3.2: Incomplete Verification","text":"<p>Definition: Agent claims completion without checking all requirements.</p> <p>In 20 Questions: Guessing without verifying the guess is consistent with all Q&amp;A history.</p> <p>Trajectories: T7</p>"},{"location":"mast/fm3/#example_1","title":"Example","text":"<p>Agent guesses \"Cat\" at turn 6:</p> <pre><code>Q1: \"Is it alive?\" \u2192 YES       \u2713 Cat is alive\nQ2: \"Is it a mammal?\" \u2192 YES    \u2713 Cat is a mammal\nQ3: \"Is it wild?\" \u2192 NO         \u2713 Cat is domestic\nQ4: \"Does it fly?\" \u2192 YES       \u2717 Cat doesn't fly!\n</code></pre> <p>The agent didn't verify Q4 before guessing.</p>"},{"location":"mast/fm3/#detection_1","title":"Detection","text":"<pre><code>def detect_fm32(trajectory):\n    for turn in trajectory.turns:\n        if turn.guess:\n            # Check if guess is consistent with all answers\n            # (This requires access to the bitmask)\n            if not verify_consistency(turn.guess, trajectory):\n                return True\n    return False\n</code></pre>"},{"location":"mast/fm3/#fm-33-incorrect-verification","title":"FM-3.3: Incorrect Verification","text":"<p>Definition: Agent claims to have verified but the verification is wrong.</p> <p>In 20 Questions: Providing a <code>verification_claim</code> that incorrectly asserts consistency.</p> <p>Trajectories: T8 (with <code>wrong_guess</code> overlay)</p>"},{"location":"mast/fm3/#example_2","title":"Example","text":"<pre><code>{\n  \"turn\": 4,\n  \"guess\": {\n    \"secret\": \"Watermelon\",\n    \"confidence\": 0.9,\n    \"verification_claim\": \"The secret must be 'Watermelon' because\n      the answer to 'Is it used for leisure?' was Yes,\n      which is consistent with 'Watermelon'.\"\n  },\n  \"guess_correct\": false\n}\n</code></pre> <p>The error: \"Consistent with Watermelon\" is true, but so are Horse and Dog. Consistency \u2260 uniqueness.</p>"},{"location":"mast/fm3/#why-this-is-the-canonical-rl-example","title":"Why This is the Canonical RL Example","text":"<p>T8/FM-3.3 provides:</p> <ol> <li>Explicit failure: <code>guess_correct=false</code></li> <li>Stated reasoning: <code>verification_claim</code> to critique</li> <li>Recovery: Game continues, correct guess follows</li> <li>Training signal: \"When you claim X is verified, check that X is the only consistent item\"</li> </ol>"},{"location":"mast/fm3/#detection_2","title":"Detection","text":"<pre><code>def detect_fm33(trajectory):\n    for turn in trajectory.turns:\n        if turn.guess:\n            has_claim = turn.guess.verification_claim is not None\n            is_wrong = not turn.guess_correct\n            if has_claim and is_wrong:\n                return True\n    return False\n</code></pre>"},{"location":"mast/fm3/#summary-table","title":"Summary Table","text":"Mode Failure Detection Signal Trajectory FM-3.1 Early stop stop at H &gt; 1 bit T3, T7 FM-3.2 Incomplete check Inconsistent guess T7 FM-3.3 Wrong verification claim + wrong guess T8"},{"location":"mast/fm3/#termination-decision-tree","title":"Termination Decision Tree","text":"<pre><code>Should I guess?\n\u2502\n\u251c\u2500 |S| = 1? \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 YES \u2192 GUESS (rational)\n\u2502\n\u251c\u2500 |S| &gt; 1 and confident? \u2500\u2500 RISKY\n\u2502   \u2502\n\u2502   \u251c\u2500 Verified ALL Q&amp;A? \u2500\u2500\u2500 YES \u2192 GUESS (FM-3.2 if wrong)\n\u2502   \u2502\n\u2502   \u2514\u2500 Claimed verified? \u2500\u2500\u2500 YES \u2192 FM-3.3 if wrong\n\u2502\n\u2514\u2500 |S| &gt; 1 and uncertain? \u2500\u2500 ASK another question\n</code></pre>"},{"location":"mast/fm3/#training-implications","title":"Training Implications","text":"<p>For FM-3 failures, reward should penalize:</p> <ol> <li>Premature stop: -entropy_at_stop</li> <li>Wrong guess: -confidence (more confident = worse)</li> <li>False verification: -1 if <code>verification_claim</code> and <code>!guess_correct</code></li> </ol>"},{"location":"overlays/prediction/","title":"Prediction Overlays","text":"<p>Prediction overlays operate on the belief-report channel - they determine what the model claims to believe about the oracle's answer.</p>"},{"location":"overlays/prediction/#available-overlays","title":"Available Overlays","text":""},{"location":"overlays/prediction/#calibrated-default","title":"calibrated (default)","text":"<p>Predicts the majority answer with calibrated confidence.</p> <pre><code>predicted_answer = (p_yes &gt;= 0.5)\nconfidence = abs(p_yes - 0.5) * 2\n</code></pre> <p>Tag: <code>pred:calibrated_argmax</code></p> p_yes Prediction Confidence 0.8 YES 0.6 0.5 random 0.0 0.3 NO 0.4"},{"location":"overlays/prediction/#overconfident","title":"overconfident","text":"<p>Same prediction as calibrated, but always high confidence.</p> <pre><code>predicted_answer = (p_yes &gt;= 0.5)\nconfidence = 0.95  # fixed\n</code></pre> <p>Tag: <code>pred:overconfident</code></p>"},{"location":"overlays/prediction/#always_yes","title":"always_yes","text":"<p>Always predicts YES regardless of split ratio.</p> <p>Tag: <code>pred:always_yes</code></p>"},{"location":"overlays/prediction/#sticky","title":"sticky","text":"<p>Persists previous high-confidence predictions even when evidence changes.</p> <p>Tag: <code>pred:sticky</code></p>"},{"location":"overlays/prediction/#commit_early","title":"commit_early","text":"<p>Locks to MAP estimate after entropy drops below threshold.</p> <p>Tag: <code>pred:commit_early</code></p>"},{"location":"overlays/prediction/#refuses_revise","title":"refuses_revise","text":"<p>Keeps wrong answer for K turns after contradiction.</p> <p>Tag: <code>pred:refuses_revise</code></p>"},{"location":"overlays/prediction/#usage","title":"Usage","text":"<pre><code># Single overlay\npython run.py single --type T6 --overlay overconfident\n\n# Multiple overlays (priority order)\npython run.py single --type T6 --overlay sticky overconfident\n</code></pre>"},{"location":"overlays/prediction/#composition","title":"Composition","text":"<p>Overlays are tried in priority order. The first overlay that returns a prediction wins.</p> <pre><code>chain = OverlayChain(\n    prediction_overlays=[\n        StickyOverlay(priority=100),      # tried first\n        CalibratedOverlay(priority=0),    # fallback\n    ]\n)\n</code></pre>"},{"location":"overlays/termination/","title":"Termination Overlays","text":"<p>Termination overlays operate on the action channel - they determine when the model attempts to stop/guess and whether the environment accepts.</p>"},{"location":"overlays/termination/#available-overlays","title":"Available Overlays","text":""},{"location":"overlays/termination/#rational-default","title":"rational (default)","text":"<p>Guesses when feasible set is singleton.</p> <pre><code>if feasible_set_size == 1:\n    action = \"guess\"\n    confidence = 1.0\n</code></pre> <p>Tag: <code>term:rational</code></p>"},{"location":"overlays/termination/#premature_stop","title":"premature_stop","text":"<p>Forces stop/guess when entropy is still high.</p> <pre><code>if entropy &gt;= threshold and turn &gt;= min_turn:\n    action = \"stop\"\n    stop_reason = f\"Premature stop at H={entropy:.2f} bits\"\n</code></pre> <p>Tag: <code>term:premature_stop</code></p> <p>Parameters:</p> <ul> <li><code>entropy_threshold</code>: Stop if H \u2265 this (default: 4.0 bits)</li> <li><code>feasible_threshold</code>: Stop if |S| \u2265 this (default: 16)</li> <li><code>min_turn</code>: Don't stop before this turn (default: 3)</li> </ul>"},{"location":"overlays/termination/#unaware","title":"unaware","text":"<p>Continues questioning past when it should stop.</p> <pre><code>if feasible_set_size &lt;= threshold:\n    # Should stop, but continues for extra_turns more\n    action = \"continue\"\n</code></pre> <p>Tag: <code>term:unaware</code></p>"},{"location":"overlays/termination/#wrong_guess","title":"wrong_guess","text":"<p>Forces an incorrect guess with false verification claim.</p> <pre><code># Pick a wrong secret\nwrong_index = random.choice([i for i in range(128) if i != secret_index])\n\naction = \"guess\"\nguess = Guess(\n    secret=items[wrong_index],\n    confidence=0.9,\n    verification_claim=\"The secret must be X because...\"\n)\n</code></pre> <p>Tag: <code>term:wrong_guess</code></p> <p>Additional tag: <code>verify:claim_present</code> (auto-added when verification_claim exists)</p>"},{"location":"overlays/termination/#usage","title":"Usage","text":"<pre><code># For FM-3.1 (premature termination)\npython run.py single --type T7 --termination premature_stop\n\n# For FM-3.3 (incorrect verification)\npython run.py single --type T8 --termination wrong_guess\n</code></pre>"},{"location":"overlays/termination/#key-fields","title":"Key Fields","text":"Field Type Description <code>model_action</code> string \"continue\", \"guess\", or \"stop\" <code>guess</code> object Guess details if action=\"guess\" <code>guess_correct</code> bool Whether guess matched secret <code>stop_reason</code> string Why the model stopped <code>stop_accepted</code> bool Whether environment accepted the stop"},{"location":"overlays/termination/#stop-acceptance-semantics","title":"Stop Acceptance Semantics","text":"<ul> <li><code>stop_accepted=true</code>: Terminal action on final turn</li> <li><code>stop_accepted=false</code>: Stop attempted but rejected (game continues)</li> <li><code>stop_accepted=null</code>: No stop attempted</li> </ul> <p>This allows trajectories to include rejected stop attempts that the agent must recover from.</p>"},{"location":"rl/canonical-example/","title":"Canonical RL Example","text":"<p>This page illustrates how a single trajectory provides training signal for reinforcement learning.</p>"},{"location":"rl/canonical-example/#the-setup","title":"The Setup","text":"<p>State space = (entropy, feasible set size, turn history)</p> <p>Action space = {ASK(question), GUESS(item)}</p> <p>Reward = +1 correct guess, -1 wrong guess, 0 otherwise</p>"},{"location":"rl/canonical-example/#example-trajectory-t8_e5f3ff15","title":"Example Trajectory: T8_e5f3ff15","text":"<p>Secret: Horse (index 56)</p> Turn State (H, |S|) Action Reward 1 (7.0, 128) ASK(\"leisure activities?\") 0 2 (6.0, 64) ASK(\"professional purposes?\") 0 3 (5.0, 32) ASK(\"found in a store?\") 0 4 (2.3, 5) GUESS(\"Watermelon\") -1 5 (1.6, 3) ASK(\"smaller than car?\") 0 6 (0.0, 1) GUESS(\"Horse\") +1"},{"location":"rl/canonical-example/#the-failure-point-turn-4","title":"The Failure Point (Turn 4)","text":"<pre><code>{\n  \"turn\": 4,\n  \"entropy_after\": 1.58,\n  \"feasible_set_size_after\": 3,\n  \"model_action\": \"guess\",\n  \"guess\": {\n    \"secret\": \"Watermelon\",\n    \"confidence\": 0.9,\n    \"verification_claim\": \"The secret must be 'Watermelon' because\n      the answer to 'Is it something used for leisure-time activities?'\n      was Yes, which is consistent with 'Watermelon'.\"\n  },\n  \"guess_correct\": false,\n  \"stop_accepted\": false\n}\n</code></pre>"},{"location":"rl/canonical-example/#what-went-wrong","title":"What went wrong?","text":"<ol> <li>Entropy too high: H = 1.58 bits means ~3 items remain</li> <li>Overconfident: Claimed 90% confidence when true probability \u2248 33%</li> <li>False verification: Claimed consistency, but 2 other items are also consistent</li> </ol>"},{"location":"rl/canonical-example/#the-learning-signal","title":"The Learning Signal","text":""},{"location":"rl/canonical-example/#negative-signal-turn-4","title":"Negative signal (Turn 4)","text":"<pre><code>state:  H=1.58 bits, |S|=3\naction: GUESS(\"Watermelon\", conf=0.9)\nreward: -1\n</code></pre> <p>Lesson: \"At H \u2248 1.5 bits, GUESS yields negative reward. Prefer ASK.\"</p>"},{"location":"rl/canonical-example/#positive-signal-turn-6","title":"Positive signal (Turn 6)","text":"<pre><code>state:  H=0 bits, |S|=1\naction: GUESS(\"Horse\", conf=1.0)\nreward: +1\n</code></pre> <p>Lesson: \"At H = 0 bits, GUESS yields positive reward.\"</p>"},{"location":"rl/canonical-example/#reward-shaping-options","title":"Reward Shaping Options","text":"<p>The sparse reward (+1/-1) can be augmented:</p> Signal Formula Effect Information gain +IG per question Encourages informative questions Entropy penalty -H at termination Penalizes early stopping Confidence penalty -conf if wrong Penalizes overconfidence Turn cost -0.1 per turn Encourages efficiency"},{"location":"rl/canonical-example/#example-calibration-aware-reward","title":"Example: Calibration-aware reward","text":"<pre><code>if action == GUESS:\n    if correct:\n        reward = +1\n    else:\n        # Penalize proportional to confidence\n        reward = -confidence  # -0.9 for this example\n</code></pre> <p>This teaches the agent: \"If you're going to be wrong, at least be uncertain about it.\"</p>"},{"location":"rl/canonical-example/#why-t8-is-canonical","title":"Why T8 is Canonical","text":"<p>T8 trajectories include:</p> <ol> <li>Explicit failure - <code>guess_correct=false</code></li> <li>Stated reasoning - <code>verification_claim</code> to critique</li> <li>Recovery - Game continues, correct guess follows</li> <li>Measurable state - Entropy at failure is recorded</li> </ol> <p>This makes them ideal for teaching because failure and correction are both present in the same trajectory.</p>"},{"location":"rl/reward-shaping/","title":"Reward Shaping","text":"<p>Different reward functions emphasize different failure modes.</p>"},{"location":"rl/reward-shaping/#sparse-reward-baseline","title":"Sparse Reward (Baseline)","text":"<pre><code>reward = +1 if guess_correct else -1 if guessed else 0\n</code></pre> <p>Pros: Simple, clear signal Cons: Sparse, slow learning</p>"},{"location":"rl/reward-shaping/#dense-reward-options","title":"Dense Reward Options","text":""},{"location":"rl/reward-shaping/#information-gain-reward","title":"Information Gain Reward","text":"<p>Rewards informative questions:</p> <pre><code>reward = information_gain(question, state)\n# IG = H(before) - H(after)\n</code></pre> <p>Best for: FM-1.3 (redundant loop), T4 trajectories</p>"},{"location":"rl/reward-shaping/#entropy-penalty","title":"Entropy Penalty","text":"<p>Penalizes stopping with high uncertainty:</p> <pre><code>if action == STOP or action == GUESS:\n    reward = -entropy_at_stop\n</code></pre> <p>Best for: FM-3.1 (premature termination), T3/T7 trajectories</p>"},{"location":"rl/reward-shaping/#calibration-reward","title":"Calibration Reward","text":"<p>Penalizes confident wrong guesses:</p> <pre><code>if guess_correct:\n    reward = +1\nelse:\n    reward = -confidence  # more confident = worse\n</code></pre> <p>Best for: FM-3.3 (incorrect verification), T8 trajectories</p>"},{"location":"rl/reward-shaping/#efficiency-bonus","title":"Efficiency Bonus","text":"<p>Rewards faster solutions:</p> <pre><code>reward = +1 - 0.1 * num_turns  # if correct\nreward = -1                     # if wrong\n</code></pre> <p>Best for: General efficiency, avoiding T4-style waste</p>"},{"location":"rl/reward-shaping/#composite-rewards","title":"Composite Rewards","text":"<p>Combine signals for multi-objective learning:</p> <pre><code>reward = (\n    +1.0 * correct_guess\n    - 1.0 * wrong_guess\n    + 0.1 * information_gain\n    - 0.05 * per_turn_cost\n    - 0.5 * (confidence if wrong_guess else 0)\n)\n</code></pre>"},{"location":"rl/reward-shaping/#trajectory-specific-recommendations","title":"Trajectory-Specific Recommendations","text":"Type Primary Failure Recommended Reward T4 Low IG questions +IG per turn T3/T7 Premature stop -H at termination T8 Wrong confident guess -conf if wrong T2/T6 Miscalibration Brier score penalty"}]}